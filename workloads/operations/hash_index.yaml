# Represent a hash index split into lookups and updates.

# The index is inspired by the PMem hash-index Dash (Lu et al., PVLDB 13(8), 2020).
# Dash has 256 Byte buckets and performs two stores for each insert.
# We represent this with an initial bucket lookup (with varying size), followed by two cache line sized writes.
# The writes are followed by a CLWB + SFENCE as in the original paper.
# We also vary the number of threads.
hash_index_update:
  matrix:
    number_threads: [ 1, 8, 16, 32 ]
    # Represent bucket sizes 64, 256, 1024
    custom_operations:
      - "r_128,w_64_cache_64,w_64_cache_-64"
      - "r_512,w_64_cache_128,w_64_cache_-128"
      - "r_1024,w_64_cache_256,w_64_cache_-256"

  args:
    memory_range: 10G
    number_operations: 100000000
    exec_mode: custom

# Based on Dash's displacement bucket design, we read two consecutive buckets for each lookup.
# We double the sizes of the buckets used in the build benchmark to represent this.
hash_index_lookup:
  matrix:
    number_threads: [ 1, 8, 16, 32 ]
    # Represent bucket sizes 64, 256, 1024
    custom_operations:
      - "r_128"
      - "r_512"
      - "r_1024"

  args:
    memory_range: 10G
    number_operations: 200000000
    exec_mode: custom
